{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext,Row\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import SparkContext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "dataDir = \"/home/satvik/Analytics/Recommender Project\"\n",
    "\n",
    "userData = sc.textFile(dataDir+\"/ml-100k/u.user\").map(lambda x : x.split(\"|\"))    #Data of all users including age, gender, occupation\n",
    "movieData = sc.textFile(dataDir+\"/ml-100k/u.item\").map(lambda x : x.split(\"|\"))   #Data of all movies including genres  \n",
    "ratingData = sc.textFile(dataDir+\"/ml-100k/u.data\").map(lambda x : x.split(\"\\t\")) #Data of all available user to movie ratings (from 1 to 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userID = 455   #Sample userID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userWatchedMoviesRatings = ratingData.filter(lambda x: int(x[0]) == userID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movieData = movieData.map(lambda x: list(x[i] for i in ([0]+range(6,24))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userWatchedMovies = userWatchedMoviesRatings.map(lambda x : int(x[1]))\n",
    "userWatchedMovies = userWatchedMovies.collect()\n",
    "userWatchedMoviesData = movieData.filter(lambda x: int(x[0]) in userWatchedMovies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'455', u'135', u'5', u'879111248'],\n",
       " [u'455', u'629', u'3', u'879111371'],\n",
       " [u'455', u'293', u'4', u'879109110'],\n",
       " [u'455', u'755', u'3', u'879112189']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userWatchedMoviesRatings.take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidDist( x,y ):\n",
    "    return np.sqrt(np.sum(np.subtract(x,y)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4721359549995796"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidDist([5,4,3],[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named pyspark_knn.ml.classification",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-5cbbde2acb56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark_knn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKNNClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named pyspark_knn.ml.classification"
     ]
    }
   ],
   "source": [
    "from pyspark_knn.ml.classification import KNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
